{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tarea 3 \n",
    "### Implementar LDA y LDAseq a tav茅s de Gensim\n",
    "\n",
    "Fernanda Weiss \n",
    "201373536-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 1: Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "En el presente trabajo se trabajar谩 con Gensim, una colecci贸n de varios scripts dise帽ados en Python, con el fin de trabajar con grandes colecciones de texto, usando streaming de datos y algoritmos incrementales eficientes, siendo esta la gran diferenciaci贸n con el resto de los paquetes cient铆ficos. \n",
    "\n",
    "Gensim ser谩 utilizado con  un corpus preprocesado de noticias recogidas durante marzo, abril y mayo del 2016, tomando como t贸picos pol铆tica, deporte, negocios, tecnolog铆a y entretenimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:35.547947. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.models import ldamodel\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:38.781976. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#Cargar el corpus y su respectivo diccionario en python.\n",
    "corpus = bleicorpus.BleiCorpus('Tarea3/corpus_lda/corpus_lda.lda_c')\n",
    "dictionary = Dictionary.load('Tarea3/corpus_lda/corpus_lda.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 2: LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Primera pregunta)\n",
    "Latent Dirichlet Allocation (LDA) es un modelo generativo probabil铆stico de un corpus, en donde se tiene que cada documento del corpus es representado como una mezcla de t贸picos latentes. Estos t贸picos hacen referencia a los temas que se tratan en el corpus, y el hecho que se denominen latentes es debido a que no son observados directamente en los documentos ni en el corpus. Adem谩s cada uno de estos t贸picos est谩 conformado por una distribuci贸n sobre la palabras del vocabulario.\n",
    "El modelo de LDA trabaja el proceso generativo de la siguiente forma para cada documento *d* en el corpus:\n",
    "1. El largo *N* del documento *d* se comporta como una distribuci贸n de Poisson: $N$ ~ $Poisson()$\n",
    "2. Los t贸picos $\\theta$ del documento *d* se comportan como una distribuci贸n de Dirichlet, que indica la proporci贸n de los t贸picos en *d*: $\\theta$~$Dirichlet(\\alpha)$  \n",
    "3. Para cada palabra $w_i$ del documento *d*:\n",
    "   1. Tomar un t贸pico $z_i$ que se comporta como una distribuci贸n Multinomial de todos los t贸picos de d: $z_i$~$Multinomial(\\theta)$\n",
    "   2. Se tiene la distribuci贸n $\\phi$ que se comporta como una distribuci贸n de Dirichlet de \\beta sobre el t贸pico $z_i$: $\\phi$~$Dirichlet(\\beta_{z_i})$\n",
    "   3. Toma la palabra $w_i$ que se comporta como una distribuci贸n Multinomial: $w_i$~$Multinomial(\\phi)$\n",
    "\n",
    "Del modelo generativo es posible notar que se LDA tiene como par谩metros del proceso a $z_i$ y $\\theta$ . Sin embargo, se necesita de otros par谩metros, $\\alpha$ y $\\beta$, llamado hiper-par谩metros para poder obtener los par谩metro propios de LDA. Es importante mencionar que para estos hiper-par谩metros se asume simetr铆a es decir que para todo el modelo generativo $\\alpha$ y $\\beta$ ser谩n los mismos y positivos.\n",
    "\n",
    "![imagen1 lda](lda.png)\n",
    "\n",
    "La Imagen 1 es la representaci贸n de LDA mediante plate notation (notaci贸n de plato), que muestra el proceso generativo descrito anteriormente. \n",
    "Cada c铆rculo representa una variable aleatoria, seg煤n su distribuci贸n de probabilidad correspondiente, excepto para los hiper-par谩metros $\\alpha$ y $\\beta$ que son valores positivos y constantes para toda la ejecuci贸n de LDA que deben ser definidos previamente:\n",
    "* $\\theta$~$Dirichlet(\\alpha)$\n",
    "* $\\phi$~$Dirichlet(\\beta_{z_i})$ \n",
    "* $z_i$~$Multinomial(\\theta)$ \n",
    "* $w_i$~$Multinomial(\\phi)$\n",
    "\n",
    "Destacar que $w_i$ es la variable aleatoria diferente a las dem谩s debido a que es la 煤nica observada.\n",
    "\n",
    "Luego, la forma en que se va ejecutando el proceso est谩 determinado por la direcci贸n de las conexiones entre los c铆rculos, es decir, el origen de la flecha condiciona el resultado, que es el fin de la flecha. Entonces, por ejemplo, seg煤n el diagrama de $\\alpha$ se obtiene la variable aleatoria $\\theta$, lo cual se condice claramente con lo explicado anteriormente en el punto 2.\n",
    "Una vez que se entiende el orden l贸gico que sigue el diagrama, es importante saber que significan los platos (cajas rectangulares), de donde proviene el nombre de la representaci贸n. Cada plato indica que la secci贸n que encierra debe ser ejecutada repetidamente, y la cantidad de veces que debe repetirse est谩 indicada en la esquina inferior derecha de cada plato. Para LDA la cantidad de ejecuciones representan:\n",
    "* *K*: Cantidad de t贸picos a observar \n",
    "* *N*: Cantidad de palabras en todos los documentos\n",
    "* *M*: Cantidad de documentos en el corpus \n",
    "A trav茅s de esta representaci贸n es f谩cil visualizar los hiper-par谩metros, par谩metros, resultado y orden que se ejecuta LDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Segunda pregunta)\n",
    "Tal como se mencion贸 anteriormente, $\\alpha$ y $\\beta$ son hiper-par谩metros que permiten escoger los par谩metros propios de LDA. Por un lado, el hiper-par谩metro $\\alpha$ condiciona la distribuci贸n de los t贸picos para un documento *d*, en donde al tener un valor de $\\alpha$ peque帽o, $\\alpha < 1$, lo que produce es realizar sesgos por t贸pico, es decir, que los documentos est谩n dominados por algunos pocos t贸picos, por lo que sirve para trabajar con corpus de temas espec铆ficos. En el caso que $\\alpha$ sea igual a 1, lo que se logra es uniformidad sobre los t贸picos. Ahora, si $\\alpha$ toma un valor alto, $\\alpha > 1$, lo que produce es una suavizaci贸n de los t贸picos, es decir, que los documentos est谩n compuesto por una mezcla de la mayor铆a o muchos de t贸picos, por lo que sirve para trabajar con corpus de temas variados.\n",
    "Por otro lado, el hiper-par谩metro $\\beta$ condiciona la distribuci贸n de las palabras en los t贸picos. An谩logamente a $\\alpha$, para valores bajos de $\\beta$, produce sesgos por palabras dentro de los t贸picos, es decir que un t贸pico puede estar compuesto por solo algunas palabras. Mientras que para valores altos de $\\beta$, se produce una suavizaci贸n de las palabras dentro de los t贸picos, es decir que un t贸pico estar谩 compuesto por una mezcla de la mayor铆a de las palabras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Tercera pregunta)\n",
    "A continuaci贸n, se entrena el corpus usando LDA usando con la siguiente cantidad de t贸picos k = 3, 5 y 10. Adem谩s se agrega el par谩metro *id2word = dictionary* lo que parea el id de la palabra con la palabra en s铆, para que luego al visualizar la distribuci贸n de palabras en el t贸pico se muestre la palabra y no su id. \n",
    "\n",
    "Se podr铆an fijar los hiper-par谩metros $\\alpha$ y $\\beta$, sin embargo, para esta ejecuci贸n se dejar谩n por defecto, ambos sim茅tricos (constantes en toda la ejecuci贸n) con valor $\\frac{1}{num\\_topics}$.\n",
    "\n",
    "Para no repetir el entrenamiento, se guardan los resultados entregados en documentos externos, y adem谩s se almacenan en variables distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:42.889068. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#pregunta 3\n",
    "lda3 = ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary)\n",
    "lda3.save(\"res_lda/lda_3/lda_3\")\n",
    "\n",
    "lda5 = ldamodel.LdaModel(corpus, num_topics=5, id2word = dictionary)\n",
    "lda5.save(\"res_lda/lda_5/lda_5\")\n",
    "\n",
    "lda10 = ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary)\n",
    "lda10.save(\"res_lda/lda_10/lda_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#  驴Qu茅 informaci贸n puede desprender de cada t贸pico? 驴Tienen las palabras descriptivas de cada t贸pico coherencia con los documentos pertenecientes al corpus? 驴C贸mo afecta la cantidad definida de t贸picos a la distribuci贸n de estos ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Cuarta pregunta)\n",
    "Luego, para cada modelo se muestran los t贸picos con su respectiva distribuci贸n de palabras, mostrando solo las primeras 20 palabras, en vez de las 10 que se visualizar铆an por defecto.\n",
    "\n",
    "Para efecto de analizar los resultados se tratar谩n como \"palabras claves\" aquellas palabras que logren describir con certeza un tema, como que por ejemplo *government* est谩 relacionado con el tema de *politica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.003*\"time\" + 0.003*\"game\" + 0.003*\"government\" + 0.003*\"years\" + 0.002*\"last\" + 0.002*\"first\" + 0.002*\"two\" + 0.002*\"bbc\" + 0.002*\"get\" + 0.002*\"take\" + 0.002*\"still\" + 0.002*\"made\" + 0.002*\"think\" + 0.002*\"many\" + 0.002*\"good\" + 0.002*\"added\" + 0.002*\"world\" + 0.002*\"football\" + 0.002*\"make\"'),\n",
       " (1,\n",
       "  u'0.003*\"years\" + 0.003*\"time\" + 0.003*\"could\" + 0.003*\"last\" + 0.002*\"get\" + 0.002*\"government\" + 0.002*\"two\" + 0.002*\"first\" + 0.002*\"like\" + 0.002*\"make\" + 0.002*\"next\" + 0.002*\"blair\" + 0.002*\"three\" + 0.002*\"home\" + 0.002*\"many\" + 0.002*\"minister\" + 0.002*\"way\" + 0.002*\"bbc\" + 0.002*\"well\" + 0.002*\"election\"'),\n",
       " (2,\n",
       "  u'0.004*\"last\" + 0.003*\"could\" + 0.003*\"first\" + 0.003*\"years\" + 0.003*\"made\" + 0.003*\"two\" + 0.002*\"film\" + 0.002*\"government\" + 0.002*\"number\" + 0.002*\"world\" + 0.002*\"make\" + 0.002*\"music\" + 0.002*\"many\" + 0.002*\"back\" + 0.002*\"top\" + 0.002*\"three\" + 0.002*\"time\" + 0.002*\"game\" + 0.002*\"well\" + 0.002*\"like\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:05:13.095352. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "num_words = 20 #por defecto son 10\n",
    "\n",
    "lda3.print_topics(3, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para el primer entrenamiento, es posible visualizar los 3 t贸picos (0, 1 y 2). De estos, es notoria la baja proporci贸n de cada palabra en cada t贸picos. Es m谩s, de los 3 t贸picos, la palabra con mayor probabilidad es *could* y *last* con 0.004 en el primer y tercer t贸pico respectivamente, sin ser est谩s palabras descriptivasal momento de an谩lisis. \n",
    "\n",
    "Es posible notar que ning煤n t贸pico entrega informaci贸n realmente descriptiva sobre el tema que se esta hablando, es decir, los resultados no son buenos. Teniendo esto en cuenta, se podr铆a mencionar que:\n",
    "* En el primer t贸pico est谩 mezclado entre deporte y pol铆tica, debido a que dentro de las palabras con mayor proporci贸n est谩n por un lado *game* y *football*, y por otro *government*, que son consideradas palabras claves dentro de cada tema.\n",
    "* En el segundo t贸pico se podr铆a decir que el t贸pico trata sobre pol铆tica dado que tiene palabras como *government*, *first*, *blair*, *minister* y *election*, pues Tony Blair fue Primer Ministro de Reino Unido.\n",
    "* En el tercer t贸pico se podr铆a decir que est谩 mayormente relacionado con entretenimiento, dado que tiene palabras claves como *film*, *music* y *game*. Sin embargo, tiene palabras de otros temas como pol铆tica con *government* o deporte si es que se considera *game* de este tema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.004*\"two\" + 0.003*\"first\" + 0.003*\"last\" + 0.003*\"make\" + 0.002*\"time\" + 0.002*\"years\" + 0.002*\"bbc\" + 0.002*\"like\" + 0.002*\"well\" + 0.002*\"world\" + 0.002*\"three\" + 0.002*\"number\" + 0.002*\"games\" + 0.002*\"says\" + 0.002*\"game\" + 0.002*\"may\" + 0.002*\"government\" + 0.002*\"players\" + 0.002*\"news\"'),\n",
       " (1,\n",
       "  u'0.004*\"could\" + 0.003*\"years\" + 0.003*\"government\" + 0.003*\"world\" + 0.003*\"may\" + 0.002*\"two\" + 0.002*\"first\" + 0.002*\"get\" + 0.002*\"many\" + 0.002*\"time\" + 0.002*\"bbc\" + 0.002*\"last\" + 0.002*\"made\" + 0.002*\"way\" + 0.002*\"say\" + 0.002*\"game\" + 0.002*\"film\" + 0.002*\"make\" + 0.002*\"good\" + 0.002*\"back\"'),\n",
       " (2,\n",
       "  u'0.004*\"first\" + 0.003*\"government\" + 0.003*\"last\" + 0.003*\"make\" + 0.002*\"many\" + 0.002*\"show\" + 0.002*\"years\" + 0.002*\"could\" + 0.002*\"get\" + 0.002*\"bbc\" + 0.002*\"made\" + 0.002*\"film\" + 0.002*\"back\" + 0.002*\"added\" + 0.002*\"time\" + 0.002*\"well\" + 0.002*\"two\" + 0.002*\"want\" + 0.002*\"public\" + 0.002*\"music\"'),\n",
       " (3,\n",
       "  u'0.004*\"last\" + 0.004*\"could\" + 0.003*\"time\" + 0.003*\"game\" + 0.003*\"years\" + 0.003*\"government\" + 0.003*\"number\" + 0.003*\"music\" + 0.002*\"two\" + 0.002*\"three\" + 0.002*\"home\" + 0.002*\"first\" + 0.002*\"back\" + 0.002*\"made\" + 0.002*\"take\" + 0.002*\"get\" + 0.002*\"added\" + 0.002*\"many\" + 0.002*\"film\" + 0.002*\"like\"'),\n",
       " (4,\n",
       "  u'0.003*\"years\" + 0.003*\"time\" + 0.003*\"made\" + 0.003*\"last\" + 0.003*\"could\" + 0.002*\"blair\" + 0.002*\"way\" + 0.002*\"like\" + 0.002*\"show\" + 0.002*\"think\" + 0.002*\"next\" + 0.002*\"labour\" + 0.002*\"first\" + 0.002*\"two\" + 0.002*\"get\" + 0.002*\"minister\" + 0.002*\"many\" + 0.002*\"top\" + 0.002*\"well\" + 0.002*\"added\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:05:17.124412. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "lda5.print_topics(5, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo entrenamiento, es posible visualizar los 5 t贸picos (0, 1, 2, 3 y 4) encontrados, con sus respectivas distribuci贸n de palabras. Al igual que en el primer entrenamiento es posible observar la baja proporci贸n de cada palabra en cada t贸pico.\n",
    "\n",
    "A pesar que se esperar铆a que cada t贸pico hable sobre un tema del corpus, es posible observar que la informaci贸n entregada por cada t贸pico no es muy descriptiva, al igual que en el caso anterior, con 3 t贸picos. En general, las palabras mostradas con mayor proporci贸n no son muy informativas, por lo que no queda claro que es lo que se intenta representar en cada t贸pico. Sin embargo, de cada t贸pico se podr铆a decir que:\n",
    "* Primer t贸pico: Tratar铆a mayormente de deporte, debido a las palabras *games*, *game* y *players* que aparecen como \"palabras claves\", aunque la palabra *government* puede inducir a una relaci贸n entre el deporte y la pol铆tica.\n",
    "* Segundo t贸pico: No es posible decir con cierta seguridad de que trata el t贸pico, dado que tiene \"palabras claves\" como *government* relacionado con politica, *film* relacionado con entretenci贸n y *game* relacionado con deporte o entretenci贸n.\n",
    "* Tercer t贸pico: Se podr铆a decir que el t贸pico habla de entretemiento por contener palabras como *film* o *music*, pero tambi茅n estar铆a relacionado con pol铆tica debido a *government*.\n",
    "* Cuarto t贸pico: Al igual que en t贸pico anterior, se podr铆a decir que el t贸pico est谩 relacionado con entreteniemitno dado que tiene \"palabras claves\" como *film*, *music* y *game*. Aunque tambi茅n estar铆a relacionado con pol铆tica debido a *government*.\n",
    "* Quinto t贸pico: Se podr铆a pensar que el t贸pico habla de pol铆tica dado que tiene palabras como *blair*, *first* y *minister*, pues Tony Blair fue Primer Ministro de Reino Unido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.004*\"last\" + 0.003*\"first\" + 0.003*\"government\" + 0.003*\"years\" + 0.003*\"says\" + 0.002*\"get\" + 0.002*\"like\" + 0.002*\"make\" + 0.002*\"way\" + 0.002*\"bbc\" + 0.002*\"time\" + 0.002*\"blair\" + 0.002*\"work\" + 0.002*\"well\" + 0.002*\"sales\" + 0.002*\"users\" + 0.002*\"market\" + 0.002*\"games\" + 0.002*\"good\"'),\n",
       " (1,\n",
       "  u'0.004*\"years\" + 0.004*\"time\" + 0.004*\"last\" + 0.003*\"game\" + 0.003*\"could\" + 0.003*\"make\" + 0.003*\"first\" + 0.003*\"world\" + 0.003*\"club\" + 0.002*\"think\" + 0.002*\"league\" + 0.002*\"two\" + 0.002*\"good\" + 0.002*\"added\" + 0.002*\"growth\" + 0.002*\"economy\" + 0.002*\"many\" + 0.002*\"may\" + 0.002*\"three\" + 0.002*\"liverpool\"'),\n",
       " (2,\n",
       "  u'0.004*\"could\" + 0.004*\"game\" + 0.004*\"government\" + 0.003*\"last\" + 0.003*\"get\" + 0.003*\"first\" + 0.002*\"made\" + 0.002*\"time\" + 0.002*\"number\" + 0.002*\"back\" + 0.002*\"three\" + 0.002*\"two\" + 0.002*\"show\" + 0.002*\"club\" + 0.002*\"group\" + 0.002*\"may\" + 0.002*\"united\" + 0.002*\"top\" + 0.002*\"next\" + 0.002*\"make\"'),\n",
       " (3,\n",
       "  u'0.004*\"first\" + 0.003*\"last\" + 0.003*\"years\" + 0.003*\"time\" + 0.003*\"two\" + 0.003*\"many\" + 0.002*\"made\" + 0.002*\"world\" + 0.002*\"take\" + 0.002*\"added\" + 0.002*\"chelsea\" + 0.002*\"make\" + 0.002*\"get\" + 0.002*\"think\" + 0.002*\"next\" + 0.002*\"could\" + 0.002*\"minister\" + 0.002*\"like\" + 0.002*\"week\" + 0.002*\"government\"'),\n",
       " (4,\n",
       "  u'0.004*\"could\" + 0.003*\"two\" + 0.003*\"deal\" + 0.003*\"first\" + 0.002*\"film\" + 0.002*\"make\" + 0.002*\"last\" + 0.002*\"government\" + 0.002*\"get\" + 0.002*\"game\" + 0.002*\"way\" + 0.002*\"take\" + 0.002*\"still\" + 0.002*\"show\" + 0.002*\"bbc\" + 0.002*\"back\" + 0.002*\"want\" + 0.002*\"many\" + 0.002*\"next\" + 0.002*\"says\"'),\n",
       " (5,\n",
       "  u'0.004*\"government\" + 0.003*\"could\" + 0.003*\"film\" + 0.003*\"last\" + 0.003*\"years\" + 0.003*\"home\" + 0.002*\"two\" + 0.002*\"well\" + 0.002*\"labour\" + 0.002*\"time\" + 0.002*\"dont\" + 0.002*\"like\" + 0.002*\"music\" + 0.002*\"back\" + 0.002*\"bbc\" + 0.002*\"added\" + 0.002*\"award\" + 0.002*\"made\" + 0.002*\"many\" + 0.002*\"think\"'),\n",
       " (6,\n",
       "  u'0.004*\"music\" + 0.004*\"number\" + 0.003*\"years\" + 0.003*\"could\" + 0.003*\"two\" + 0.003*\"last\" + 0.003*\"band\" + 0.002*\"album\" + 0.002*\"british\" + 0.002*\"like\" + 0.002*\"time\" + 0.002*\"back\" + 0.002*\"three\" + 0.002*\"first\" + 0.002*\"world\" + 0.002*\"club\" + 0.002*\"show\" + 0.002*\"get\" + 0.002*\"film\" + 0.002*\"bbc\"'),\n",
       " (7,\n",
       "  u'0.004*\"time\" + 0.004*\"labour\" + 0.004*\"blair\" + 0.003*\"election\" + 0.003*\"two\" + 0.003*\"could\" + 0.003*\"first\" + 0.003*\"last\" + 0.003*\"made\" + 0.002*\"number\" + 0.002*\"say\" + 0.002*\"games\" + 0.002*\"three\" + 0.002*\"world\" + 0.002*\"top\" + 0.002*\"may\" + 0.002*\"years\" + 0.002*\"get\" + 0.002*\"bbc\" + 0.002*\"party\"'),\n",
       " (8,\n",
       "  u'0.003*\"many\" + 0.003*\"film\" + 0.003*\"could\" + 0.003*\"government\" + 0.003*\"last\" + 0.002*\"years\" + 0.002*\"law\" + 0.002*\"added\" + 0.002*\"bbc\" + 0.002*\"time\" + 0.002*\"top\" + 0.002*\"first\" + 0.002*\"good\" + 0.002*\"two\" + 0.002*\"like\" + 0.002*\"lord\" + 0.002*\"music\" + 0.002*\"use\" + 0.002*\"take\" + 0.002*\"minister\"'),\n",
       " (9,\n",
       "  u'0.004*\"years\" + 0.003*\"made\" + 0.003*\"last\" + 0.003*\"could\" + 0.003*\"government\" + 0.003*\"bbc\" + 0.003*\"time\" + 0.003*\"first\" + 0.002*\"game\" + 0.002*\"company\" + 0.002*\"security\" + 0.002*\"make\" + 0.002*\"two\" + 0.002*\"well\" + 0.002*\"still\" + 0.002*\"many\" + 0.002*\"service\" + 0.002*\"use\" + 0.002*\"minister\" + 0.002*\"way\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:29:23.741746. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "lda10.print_topics(10, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el tercer entrenamiento, es posible visualizar los 10 t贸picos (0, 1, 2,..., 9) encontrados, con sus respectivas distribuci贸n de palabras. Al igual que en los entrenamiento anteriores es posible observar la baja proporci贸n de cada palabra en cada t贸pico.\n",
    "\n",
    "Es posible observar que la mayor parte de la informaci贸n entregada por cada t贸pico no es muy descriptiva, al igual que en los casos anterior. En general, las palabras mostradas con mayor proporci贸n no son muy informativas, por lo que no queda claro que es lo que se intenta representar en cada t贸pico. A pesar de esto,  se podr铆a decir de cada t贸pico que:\n",
    "\n",
    "* Primer t贸pico: Es un t贸pico bien variado, que contiene informaci贸n sobre pol铆tica debido a la aparici贸n de las palabras *government* y *blair*, adem谩s contiene informaci贸n sobre negocios por palabras como *work*, *market* y *sales*, y tambi茅n se podr铆a pensar que se est谩 hablando de tecnolog铆a por la palabra *users* y de entretenci贸n o deporte por *games*. \n",
    "* Segundo t贸pico: En este t贸pico se estar铆a hablando mayormente sobre deporte, por palabras como *game*, *club*, *league* y *liverpool*, pero tambi茅n estar铆a relacionado con negocios o pol铆tica por la palabra *economy*. \n",
    "* Tercer t贸pico: Este t贸pico tambi茅n tendr铆a m谩s presente el tema deporte (*game*, *club*) pero no tan marcadamente como en el t贸pico anterior.         \n",
    "* Cuarto t贸pico: El t贸pico tendr铆a m谩s presente el tema pol铆tico debido a palabras clave como *minister* y *government*, a pesar que estas aparezcan con menor probabiliad que las otras palabras, pues ellas no son informativas.\n",
    "* Quinto t贸pico: film government game \n",
    "* Sexto t贸pico: governmen film music award\n",
    "* Septimo t贸pico: music band album british club film -> claramente entrtencion\n",
    "* Octavo t贸pico: blair election games party\n",
    "* Noveno t贸pico: film government law lord music minister -> politica con un poco de entretenci贸n xd\n",
    "* D茅cimo t贸pico: government game company security minister\n",
    "\n",
    "Se esperaria que el topico 5 es mejor y cada uno represente un tema ...\n",
    "10 topicos aparecen nuevas palabras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 3: Dynamic Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Dynamic Topic Models (DTM) tambi茅n es un modelo generativo extendido de LDA, pero que a diferencia de 茅ste permite analizar la evoluci贸n de los t贸picos en un corpus a trav茅s del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Primera pregunta)\n",
    "Primero se procede a entrenar nuevamente el corpus entregado, pero esta vez utilizando el algoritmo LdaSeq, el cual est谩 basado en el c贸digo orginal de DTM de Blei. Para el entrenamiento se utilizar谩n 5 t贸picos con una varianza *0.001*, y adem谩s se debe entregar como par谩metro la cantidad de documentos por intervalo de tiempo, que en este caso ser铆an los documentos para cada mes, con 3 intervalos de tiempo, dado que los documentos pertenecen a 3 meses (marzo, abril y mayo): 438 documentos para el primer intervalo, 430 para e segundo intervalo y 456 para el 煤ltimo intervalo.\n",
    "\n",
    "Al igual que el LDA, se introduce el par谩metro *id2word=dictionary* en la ejecuci贸n, para realizar el pareo entre el id de las palabras del diccionario y las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 23:20:21.065411. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import ldaseqmodel\n",
    "\n",
    "time_slice = [438, 430, 456]\n",
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5, chain_variance = 0.001)\n",
    "ldaseq.save(\"res_ldaseq/ldaseq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Segunda pregunta Para cada uno de los intervalos de tiempo, observe la distribuci贸n topic_word de cada t贸pico 驴Que puede observar en la evoluci贸n de estos?)\n",
    "\n",
    "A continuaci贸n se muestra el resultado de obtenido de LdaSeq, el cual entrega todos los t贸picos en un intervalo de tiempo espec铆fico, dado que la ejecuci贸n solo se realiz贸 con 5 t贸picos, la 煤nca variaci贸n es el intervalo de tiempo a visualizar. La cantidad de palabras a mostrar para cada t贸pico ser谩n las por defecto, 20.\n",
    "\n",
    "En el primer intervalo, que se asume el marzo de 2016 se obtiene la siguiente distribuci贸n de palabras para cada t贸pico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(u'market', 0.005),\n",
      "  (u'last', 0.004),\n",
      "  (u'government', 0.004),\n",
      "  (u'years', 0.004),\n",
      "  (u'growth', 0.004),\n",
      "  (u'economy', 0.004),\n",
      "  (u'economic', 0.003),\n",
      "  (u'could', 0.003),\n",
      "  (u'bank', 0.003),\n",
      "  (u'company', 0.003),\n",
      "  (u'oil', 0.003),\n",
      "  (u'sales', 0.003),\n",
      "  (u'prices', 0.003),\n",
      "  (u'however', 0.003),\n",
      "  (u'firm', 0.003),\n",
      "  (u'may', 0.003),\n",
      "  (u'rise', 0.003),\n",
      "  (u'shares', 0.002),\n",
      "  (u'business', 0.002),\n",
      "  (u'european', 0.002)],\n",
      " [(u'could', 0.006),\n",
      "  (u'use', 0.005),\n",
      "  (u'technology', 0.005),\n",
      "  (u'many', 0.005),\n",
      "  (u'users', 0.005),\n",
      "  (u'games', 0.004),\n",
      "  (u'online', 0.004),\n",
      "  (u'information', 0.004),\n",
      "  (u'mobile', 0.004),\n",
      "  (u'net', 0.004),\n",
      "  (u'software', 0.004),\n",
      "  (u'service', 0.003),\n",
      "  (u'used', 0.003),\n",
      "  (u'get', 0.003),\n",
      "  (u'using', 0.003),\n",
      "  (u'make', 0.003),\n",
      "  (u'computer', 0.003),\n",
      "  (u'phone', 0.003),\n",
      "  (u'digital', 0.003),\n",
      "  (u'internet', 0.003)],\n",
      " [(u'game', 0.009),\n",
      "  (u'club', 0.007),\n",
      "  (u'chelsea', 0.007),\n",
      "  (u'players', 0.006),\n",
      "  (u'united', 0.006),\n",
      "  (u'league', 0.006),\n",
      "  (u'football', 0.005),\n",
      "  (u'arsenal', 0.005),\n",
      "  (u'cup', 0.005),\n",
      "  (u'play', 0.005),\n",
      "  (u'win', 0.005),\n",
      "  (u'time', 0.004),\n",
      "  (u'manager', 0.004),\n",
      "  (u'back', 0.004),\n",
      "  (u'first', 0.004),\n",
      "  (u'goal', 0.004),\n",
      "  (u'liverpool', 0.004),\n",
      "  (u'team', 0.004),\n",
      "  (u'last', 0.004),\n",
      "  (u'good', 0.004)],\n",
      " [(u'film', 0.01),\n",
      "  (u'music', 0.009),\n",
      "  (u'show', 0.007),\n",
      "  (u'years', 0.006),\n",
      "  (u'number', 0.005),\n",
      "  (u'awards', 0.005),\n",
      "  (u'first', 0.005),\n",
      "  (u'last', 0.005),\n",
      "  (u'band', 0.004),\n",
      "  (u'award', 0.004),\n",
      "  (u'top', 0.004),\n",
      "  (u'album', 0.004),\n",
      "  (u'star', 0.004),\n",
      "  (u'song', 0.004),\n",
      "  (u'two', 0.003),\n",
      "  (u'three', 0.003),\n",
      "  (u'including', 0.003),\n",
      "  (u'british', 0.003),\n",
      "  (u'director', 0.003),\n",
      "  (u'bbc', 0.003)],\n",
      " [(u'government', 0.007),\n",
      "  (u'blair', 0.006),\n",
      "  (u'labour', 0.006),\n",
      "  (u'minister', 0.005),\n",
      "  (u'election', 0.005),\n",
      "  (u'party', 0.004),\n",
      "  (u'bbc', 0.004),\n",
      "  (u'could', 0.004),\n",
      "  (u'public', 0.004),\n",
      "  (u'say', 0.004),\n",
      "  (u'brown', 0.004),\n",
      "  (u'prime', 0.004),\n",
      "  (u'plans', 0.003),\n",
      "  (u'howard', 0.003),\n",
      "  (u'law', 0.003),\n",
      "  (u'says', 0.003),\n",
      "  (u'lord', 0.003),\n",
      "  (u'secretary', 0.003),\n",
      "  (u'next', 0.003),\n",
      "  (u'leader', 0.003)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:36:53.279685. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el segundo intervalo, que se asume el abril de 2016 se obtiene la siguiente distribuci贸n de palabras para cada t贸pico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'market', 0.005),\n",
       "  (u'last', 0.004),\n",
       "  (u'government', 0.004),\n",
       "  (u'years', 0.004),\n",
       "  (u'growth', 0.004),\n",
       "  (u'economy', 0.004),\n",
       "  (u'economic', 0.003),\n",
       "  (u'could', 0.003),\n",
       "  (u'bank', 0.003),\n",
       "  (u'oil', 0.003),\n",
       "  (u'company', 0.003),\n",
       "  (u'sales', 0.003),\n",
       "  (u'prices', 0.003),\n",
       "  (u'however', 0.003),\n",
       "  (u'firm', 0.003),\n",
       "  (u'may', 0.003),\n",
       "  (u'rise', 0.003),\n",
       "  (u'shares', 0.002),\n",
       "  (u'european', 0.002),\n",
       "  (u'business', 0.002)],\n",
       " [(u'could', 0.006),\n",
       "  (u'use', 0.005),\n",
       "  (u'technology', 0.005),\n",
       "  (u'many', 0.005),\n",
       "  (u'users', 0.005),\n",
       "  (u'games', 0.004),\n",
       "  (u'online', 0.004),\n",
       "  (u'information', 0.004),\n",
       "  (u'net', 0.004),\n",
       "  (u'mobile', 0.004),\n",
       "  (u'software', 0.004),\n",
       "  (u'get', 0.003),\n",
       "  (u'used', 0.003),\n",
       "  (u'service', 0.003),\n",
       "  (u'using', 0.003),\n",
       "  (u'make', 0.003),\n",
       "  (u'computer', 0.003),\n",
       "  (u'phone', 0.003),\n",
       "  (u'digital', 0.003),\n",
       "  (u'internet', 0.003)],\n",
       " [(u'game', 0.009),\n",
       "  (u'club', 0.007),\n",
       "  (u'chelsea', 0.007),\n",
       "  (u'players', 0.006),\n",
       "  (u'united', 0.006),\n",
       "  (u'league', 0.006),\n",
       "  (u'football', 0.005),\n",
       "  (u'arsenal', 0.005),\n",
       "  (u'cup', 0.005),\n",
       "  (u'win', 0.005),\n",
       "  (u'play', 0.005),\n",
       "  (u'time', 0.004),\n",
       "  (u'manager', 0.004),\n",
       "  (u'back', 0.004),\n",
       "  (u'first', 0.004),\n",
       "  (u'goal', 0.004),\n",
       "  (u'liverpool', 0.004),\n",
       "  (u'team', 0.004),\n",
       "  (u'last', 0.004),\n",
       "  (u'good', 0.004)],\n",
       " [(u'film', 0.01),\n",
       "  (u'music', 0.009),\n",
       "  (u'show', 0.007),\n",
       "  (u'years', 0.006),\n",
       "  (u'number', 0.005),\n",
       "  (u'awards', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'first', 0.005),\n",
       "  (u'top', 0.004),\n",
       "  (u'band', 0.004),\n",
       "  (u'award', 0.004),\n",
       "  (u'album', 0.004),\n",
       "  (u'star', 0.004),\n",
       "  (u'song', 0.004),\n",
       "  (u'two', 0.003),\n",
       "  (u'three', 0.003),\n",
       "  (u'including', 0.003),\n",
       "  (u'british', 0.003),\n",
       "  (u'bbc', 0.003),\n",
       "  (u'director', 0.003)],\n",
       " [(u'government', 0.007),\n",
       "  (u'blair', 0.006),\n",
       "  (u'labour', 0.006),\n",
       "  (u'minister', 0.005),\n",
       "  (u'election', 0.005),\n",
       "  (u'party', 0.004),\n",
       "  (u'bbc', 0.004),\n",
       "  (u'public', 0.004),\n",
       "  (u'could', 0.004),\n",
       "  (u'say', 0.004),\n",
       "  (u'brown', 0.004),\n",
       "  (u'prime', 0.004),\n",
       "  (u'plans', 0.003),\n",
       "  (u'howard', 0.003),\n",
       "  (u'law', 0.003),\n",
       "  (u'says', 0.003),\n",
       "  (u'lord', 0.003),\n",
       "  (u'secretary', 0.003),\n",
       "  (u'next', 0.003),\n",
       "  (u'police', 0.003)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:38:03.369407. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el 煤ltimo intervalo, que se asume el mayo de 2016 se obtiene la siguiente distribuci贸n de palabras para cada t贸pico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'market', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'government', 0.004),\n",
       "  (u'years', 0.004),\n",
       "  (u'growth', 0.004),\n",
       "  (u'economy', 0.004),\n",
       "  (u'economic', 0.003),\n",
       "  (u'could', 0.003),\n",
       "  (u'bank', 0.003),\n",
       "  (u'oil', 0.003),\n",
       "  (u'company', 0.003),\n",
       "  (u'sales', 0.003),\n",
       "  (u'however', 0.003),\n",
       "  (u'prices', 0.003),\n",
       "  (u'firm', 0.003),\n",
       "  (u'may', 0.003),\n",
       "  (u'rise', 0.003),\n",
       "  (u'shares', 0.002),\n",
       "  (u'european', 0.002),\n",
       "  (u'business', 0.002)],\n",
       " [(u'could', 0.006),\n",
       "  (u'use', 0.005),\n",
       "  (u'technology', 0.005),\n",
       "  (u'many', 0.005),\n",
       "  (u'users', 0.005),\n",
       "  (u'games', 0.004),\n",
       "  (u'online', 0.004),\n",
       "  (u'information', 0.004),\n",
       "  (u'net', 0.004),\n",
       "  (u'mobile', 0.004),\n",
       "  (u'software', 0.004),\n",
       "  (u'service', 0.003),\n",
       "  (u'used', 0.003),\n",
       "  (u'get', 0.003),\n",
       "  (u'using', 0.003),\n",
       "  (u'make', 0.003),\n",
       "  (u'phone', 0.003),\n",
       "  (u'computer', 0.003),\n",
       "  (u'digital', 0.003),\n",
       "  (u'internet', 0.003)],\n",
       " [(u'game', 0.009),\n",
       "  (u'club', 0.007),\n",
       "  (u'chelsea', 0.007),\n",
       "  (u'players', 0.006),\n",
       "  (u'united', 0.006),\n",
       "  (u'league', 0.006),\n",
       "  (u'football', 0.005),\n",
       "  (u'arsenal', 0.005),\n",
       "  (u'cup', 0.005),\n",
       "  (u'win', 0.005),\n",
       "  (u'play', 0.004),\n",
       "  (u'time', 0.004),\n",
       "  (u'manager', 0.004),\n",
       "  (u'back', 0.004),\n",
       "  (u'first', 0.004),\n",
       "  (u'goal', 0.004),\n",
       "  (u'liverpool', 0.004),\n",
       "  (u'team', 0.004),\n",
       "  (u'last', 0.004),\n",
       "  (u'manchester', 0.004)],\n",
       " [(u'film', 0.009),\n",
       "  (u'music', 0.009),\n",
       "  (u'show', 0.007),\n",
       "  (u'years', 0.006),\n",
       "  (u'number', 0.005),\n",
       "  (u'awards', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'first', 0.005),\n",
       "  (u'band', 0.004),\n",
       "  (u'top', 0.004),\n",
       "  (u'award', 0.004),\n",
       "  (u'album', 0.004),\n",
       "  (u'song', 0.004),\n",
       "  (u'star', 0.004),\n",
       "  (u'two', 0.003),\n",
       "  (u'three', 0.003),\n",
       "  (u'including', 0.003),\n",
       "  (u'british', 0.003),\n",
       "  (u'bbc', 0.003),\n",
       "  (u'chart', 0.003)],\n",
       " [(u'government', 0.007),\n",
       "  (u'blair', 0.006),\n",
       "  (u'labour', 0.006),\n",
       "  (u'minister', 0.005),\n",
       "  (u'election', 0.005),\n",
       "  (u'party', 0.004),\n",
       "  (u'bbc', 0.004),\n",
       "  (u'public', 0.004),\n",
       "  (u'say', 0.004),\n",
       "  (u'brown', 0.004),\n",
       "  (u'could', 0.004),\n",
       "  (u'prime', 0.004),\n",
       "  (u'plans', 0.003),\n",
       "  (u'howard', 0.003),\n",
       "  (u'says', 0.003),\n",
       "  (u'law', 0.003),\n",
       "  (u'lord', 0.003),\n",
       "  (u'secretary', 0.003),\n",
       "  (u'next', 0.003),\n",
       "  (u'leader', 0.003)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:38:09.769931. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Tercera pregunta Para un documento dado del corpus , obtenga la distribuci贸n de t贸picos usando el modelo entrenado y visualice el contenido de dicho documento. Analice sus observaciones. Repita el experimento con los 3 modelos generados.)\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call corpus[docid] without an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-847f39c61227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m558\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdoc_bow\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mldaseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_bow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/corpora/indexedcorpus.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, docno)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot call corpus[docid] without an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call corpus[docid] without an index"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 02:12:24.518355. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "words = [dictionary[word_id] for word_id, count in corpus[558]]\n",
    "print (words)\n",
    "doc_bow =30  #QUE ES!!!\n",
    "print (ldaseq[doc_bow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Cuarta pregunta Instale el m贸dulo pyLDAvis para visualizar el modelo generado por LDAseq se recomienda usar el paquete pip para instalar pyLDAvis. Genere una visualizaci贸n para cada intervalo de tiempo modifique el par谩metro time)  \n",
    "\n",
    "A continuaci贸n mediante el m贸dulo pyLDAvis se genera una visualizaci贸n para cada intervalo de tiempo.\n",
    "\n",
    "Para el primer intervalo de tiempo (marzo) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=0, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo intervalo de tiempo (abril) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=1, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el 煤ltimo intervalo de tiempo (mayo) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=2, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (quinta pregunta Compare los resultados obtenidos con el modelo LDA de la secci贸n anterior, con los resultados de ldaseq 驴Que modelo logra representar mejor el corpus de documentos usado? 驴Como influye en el entrenamiento de los t贸picos la consideraci贸n de los intervalos de tiempo?.)\n",
    "\n",
    "Al comparar los resultados entregados por LDA y LdaSeq es posible determinar que para este corpus son mejores los resultados entregados por el algoritmo de LdaSeq."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
