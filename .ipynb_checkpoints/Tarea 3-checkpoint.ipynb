{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tarea 3 \n",
    "### Implementar LDA y LDAseq a tavés de Gensim\n",
    "\n",
    "Fernanda Weiss \n",
    "201373536-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 1: Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "En el presente trabajo se trabajará con Gensim, una colección de varios scripts diseñados en Python, con el fin de trabajar con grandes colecciones de texto, usando streaming de datos y algoritmos incrementales eficientes, siendo esta la gran diferenciación con el resto de los paquetes científicos. \n",
    "\n",
    "Gensim será utilizado con  un corpus preprocesado de noticias recogidas durante marzo, abril y mayo del 2016, tomando como tópicos política, deporte, negocios, tecnología y entretenimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:35.547947. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.models import ldamodel\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:38.781976. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#Cargar el corpus y su respectivo diccionario en python.\n",
    "corpus = bleicorpus.BleiCorpus('Tarea3/corpus_lda/corpus_lda.lda_c')\n",
    "dictionary = Dictionary.load('Tarea3/corpus_lda/corpus_lda.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 2: LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Primera pregunta)\n",
    "Latent Dirichlet Allocation (LDA) es un modelo generativo probabilístico de un corpus, en donde se tiene que cada documento del corpus es representado como una mezcla de tópicos latentes. Estos tópicos hacen referencia a los temas que se tratan en el corpus, y el hecho que se denominen latentes es debido a que no son observados directamente en los documentos ni en el corpus. Además cada uno de estos tópicos está conformado por una distribución sobre la palabras del vocabulario.\n",
    "El modelo de LDA trabaja el proceso generativo de la siguiente forma para cada documento *d* en el corpus:\n",
    "1. El largo *N* del documento *d* se comporta como una distribución de Poisson: $N$ ~ $Poisson(𝜉)$\n",
    "2. Los tópicos $\\theta$ del documento *d* se comportan como una distribución de Dirichlet, que indica la proporción de los tópicos en *d*: $\\theta$~$Dirichlet(\\alpha)$  \n",
    "3. Para cada palabra $w_i$ del documento *d*:\n",
    "   1. Tomar un tópico $z_i$ que se comporta como una distribución Multinomial de todos los tópicos de d: $z_i$~$Multinomial(\\theta)$\n",
    "   2. Se tiene la distribución $\\phi$ que se comporta como una distribución de Dirichlet de \\beta sobre el tópico $z_i$: $\\phi$~$Dirichlet(\\beta_{z_i})$\n",
    "   3. Toma la palabra $w_i$ que se comporta como una distribución Multinomial: $w_i$~$Multinomial(\\phi)$\n",
    "\n",
    "Del modelo generativo es posible notar que se LDA tiene como parámetros del proceso a $z_i$ y $\\theta$ . Sin embargo, se necesita de otros parámetros, $\\alpha$ y $\\beta$, llamado hiper-parámetros para poder obtener los parámetro propios de LDA. Es importante mencionar que para estos hiper-parámetros se asume simetría es decir que para todo el modelo generativo $\\alpha$ y $\\beta$ serán los mismos y positivos.\n",
    "\n",
    "![imagen1 lda](lda.png)\n",
    "\n",
    "La Imagen 1 es la representación de LDA mediante plate notation (notación de plato), que muestra el proceso generativo descrito anteriormente. \n",
    "Cada círculo representa una variable aleatoria, según su distribución de probabilidad correspondiente, excepto para los hiper-parámetros $\\alpha$ y $\\beta$ que son valores positivos y constantes para toda la ejecución de LDA que deben ser definidos previamente:\n",
    "* $\\theta$~$Dirichlet(\\alpha)$\n",
    "* $\\phi$~$Dirichlet(\\beta_{z_i})$ \n",
    "* $z_i$~$Multinomial(\\theta)$ \n",
    "* $w_i$~$Multinomial(\\phi)$\n",
    "\n",
    "Destacar que $w_i$ es la variable aleatoria diferente a las demás debido a que es la única observada.\n",
    "\n",
    "Luego, la forma en que se va ejecutando el proceso está determinado por la dirección de las conexiones entre los círculos, es decir, el origen de la flecha condiciona el resultado, que es el fin de la flecha. Entonces, por ejemplo, según el diagrama de $\\alpha$ se obtiene la variable aleatoria $\\theta$, lo cual se condice claramente con lo explicado anteriormente en el punto 2.\n",
    "Una vez que se entiende el orden lógico que sigue el diagrama, es importante saber que significan los platos (cajas rectangulares), de donde proviene el nombre de la representación. Cada plato indica que la sección que encierra debe ser ejecutada repetidamente, y la cantidad de veces que debe repetirse está indicada en la esquina inferior derecha de cada plato. Para LDA la cantidad de ejecuciones representan:\n",
    "* *K*: Cantidad de tópicos a observar \n",
    "* *N*: Cantidad de palabras en todos los documentos\n",
    "* *M*: Cantidad de documentos en el corpus \n",
    "A través de esta representación es fácil visualizar los hiper-parámetros, parámetros, resultado y orden que se ejecuta LDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Segunda pregunta)\n",
    "Tal como se mencionó anteriormente, $\\alpha$ y $\\beta$ son hiper-parámetros que permiten escoger los parámetros propios de LDA. Por un lado, el hiper-parámetro $\\alpha$ condiciona la distribución de los tópicos para un documento *d*, en donde al tener un valor de $\\alpha$ pequeño, $\\alpha < 1$, lo que produce es realizar sesgos por tópico, es decir, que los documentos están dominados por algunos pocos tópicos, por lo que sirve para trabajar con corpus de temas específicos. En el caso que $\\alpha$ sea igual a 1, lo que se logra es uniformidad sobre los tópicos. Ahora, si $\\alpha$ toma un valor alto, $\\alpha > 1$, lo que produce es una suavización de los tópicos, es decir, que los documentos están compuesto por una mezcla de la mayoría o muchos de tópicos, por lo que sirve para trabajar con corpus de temas variados.\n",
    "Por otro lado, el hiper-parámetro $\\beta$ condiciona la distribución de las palabras en los tópicos. Análogamente a $\\alpha$, para valores bajos de $\\beta$, produce sesgos por palabras dentro de los tópicos, es decir que un tópico puede estar compuesto por solo algunas palabras. Mientras que para valores altos de $\\beta$, se produce una suavización de las palabras dentro de los tópicos, es decir que un tópico estará compuesto por una mezcla de la mayoría de las palabras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Tercera pregunta)\n",
    "A continuación, se entrena el corpus usando LDA usando con la siguiente cantidad de tópicos k = 3, 5 y 10. Además se agrega el parámetro *id2word = dictionary* lo que parea el id de la palabra con la palabra en sí, para que luego al visualizar la distribución de palabras en el tópico se muestre la palabra y no su id. \n",
    "\n",
    "Se podrían fijar los hiper-parámetros $\\alpha$ y $\\beta$, sin embargo, para esta ejecución se dejarán por defecto, ambos simétricos (constantes en toda la ejecución) con valor $\\frac{1}{num\\_topics}$.\n",
    "\n",
    "Para no repetir el entrenamiento, se guardan los resultados entregados en documentos externos, y además se almacenan en variables distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:03:42.889068. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#pregunta 3\n",
    "lda3 = ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary)\n",
    "lda3.save(\"res_lda/lda_3/lda_3\")\n",
    "\n",
    "lda5 = ldamodel.LdaModel(corpus, num_topics=5, id2word = dictionary)\n",
    "lda5.save(\"res_lda/lda_5/lda_5\")\n",
    "\n",
    "lda10 = ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary)\n",
    "lda10.save(\"res_lda/lda_10/lda_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#  ¿Qué información puede desprender de cada tópico? ¿Tienen las palabras descriptivas de cada tópico coherencia con los documentos pertenecientes al corpus? ¿Cómo afecta la cantidad definida de tópicos a la distribución de estos ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Cuarta pregunta)\n",
    "Luego, para cada modelo se muestran los tópicos con su respectiva distribución de palabras, mostrando solo las primeras 20 palabras, en vez de las 10 que se visualizarían por defecto.\n",
    "\n",
    "Para efecto de analizar los resultados se tratarán como \"palabras claves\" aquellas palabras que logren describir con certeza un tema, como que por ejemplo *government* está relacionado con el tema de *politica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.003*\"time\" + 0.003*\"game\" + 0.003*\"government\" + 0.003*\"years\" + 0.002*\"last\" + 0.002*\"first\" + 0.002*\"two\" + 0.002*\"bbc\" + 0.002*\"get\" + 0.002*\"take\" + 0.002*\"still\" + 0.002*\"made\" + 0.002*\"think\" + 0.002*\"many\" + 0.002*\"good\" + 0.002*\"added\" + 0.002*\"world\" + 0.002*\"football\" + 0.002*\"make\"'),\n",
       " (1,\n",
       "  u'0.003*\"years\" + 0.003*\"time\" + 0.003*\"could\" + 0.003*\"last\" + 0.002*\"get\" + 0.002*\"government\" + 0.002*\"two\" + 0.002*\"first\" + 0.002*\"like\" + 0.002*\"make\" + 0.002*\"next\" + 0.002*\"blair\" + 0.002*\"three\" + 0.002*\"home\" + 0.002*\"many\" + 0.002*\"minister\" + 0.002*\"way\" + 0.002*\"bbc\" + 0.002*\"well\" + 0.002*\"election\"'),\n",
       " (2,\n",
       "  u'0.004*\"last\" + 0.003*\"could\" + 0.003*\"first\" + 0.003*\"years\" + 0.003*\"made\" + 0.003*\"two\" + 0.002*\"film\" + 0.002*\"government\" + 0.002*\"number\" + 0.002*\"world\" + 0.002*\"make\" + 0.002*\"music\" + 0.002*\"many\" + 0.002*\"back\" + 0.002*\"top\" + 0.002*\"three\" + 0.002*\"time\" + 0.002*\"game\" + 0.002*\"well\" + 0.002*\"like\"')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:05:13.095352. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "num_words = 20 #por defecto son 10\n",
    "\n",
    "lda3.print_topics(3, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para el primer entrenamiento, es posible visualizar los 3 tópicos (0, 1 y 2). De estos, es notoria la baja proporción de cada palabra en cada tópicos. Es más, de los 3 tópicos, la palabra con mayor probabilidad es *could* y *last* con 0.004 en el primer y tercer tópico respectivamente, sin ser estás palabras descriptivasal momento de análisis. \n",
    "\n",
    "Es posible notar que ningún tópico entrega información realmente descriptiva sobre el tema que se esta hablando, es decir, los resultados no son buenos. Teniendo esto en cuenta, se podría mencionar que:\n",
    "* En el primer tópico está mezclado entre deporte y política, debido a que dentro de las palabras con mayor proporción están por un lado *game* y *football*, y por otro *government*, que son consideradas palabras claves dentro de cada tema.\n",
    "* En el segundo tópico se podría decir que el tópico trata sobre política dado que tiene palabras como *government*, *first*, *blair*, *minister* y *election*, pues Tony Blair fue Primer Ministro de Reino Unido.\n",
    "* En el tercer tópico se podría decir que está mayormente relacionado con entretenimiento, dado que tiene palabras claves como *film*, *music* y *game*. Sin embargo, tiene palabras de otros temas como política con *government* o deporte si es que se considera *game* de este tema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.004*\"two\" + 0.003*\"first\" + 0.003*\"last\" + 0.003*\"make\" + 0.002*\"time\" + 0.002*\"years\" + 0.002*\"bbc\" + 0.002*\"like\" + 0.002*\"well\" + 0.002*\"world\" + 0.002*\"three\" + 0.002*\"number\" + 0.002*\"games\" + 0.002*\"says\" + 0.002*\"game\" + 0.002*\"may\" + 0.002*\"government\" + 0.002*\"players\" + 0.002*\"news\"'),\n",
       " (1,\n",
       "  u'0.004*\"could\" + 0.003*\"years\" + 0.003*\"government\" + 0.003*\"world\" + 0.003*\"may\" + 0.002*\"two\" + 0.002*\"first\" + 0.002*\"get\" + 0.002*\"many\" + 0.002*\"time\" + 0.002*\"bbc\" + 0.002*\"last\" + 0.002*\"made\" + 0.002*\"way\" + 0.002*\"say\" + 0.002*\"game\" + 0.002*\"film\" + 0.002*\"make\" + 0.002*\"good\" + 0.002*\"back\"'),\n",
       " (2,\n",
       "  u'0.004*\"first\" + 0.003*\"government\" + 0.003*\"last\" + 0.003*\"make\" + 0.002*\"many\" + 0.002*\"show\" + 0.002*\"years\" + 0.002*\"could\" + 0.002*\"get\" + 0.002*\"bbc\" + 0.002*\"made\" + 0.002*\"film\" + 0.002*\"back\" + 0.002*\"added\" + 0.002*\"time\" + 0.002*\"well\" + 0.002*\"two\" + 0.002*\"want\" + 0.002*\"public\" + 0.002*\"music\"'),\n",
       " (3,\n",
       "  u'0.004*\"last\" + 0.004*\"could\" + 0.003*\"time\" + 0.003*\"game\" + 0.003*\"years\" + 0.003*\"government\" + 0.003*\"number\" + 0.003*\"music\" + 0.002*\"two\" + 0.002*\"three\" + 0.002*\"home\" + 0.002*\"first\" + 0.002*\"back\" + 0.002*\"made\" + 0.002*\"take\" + 0.002*\"get\" + 0.002*\"added\" + 0.002*\"many\" + 0.002*\"film\" + 0.002*\"like\"'),\n",
       " (4,\n",
       "  u'0.003*\"years\" + 0.003*\"time\" + 0.003*\"made\" + 0.003*\"last\" + 0.003*\"could\" + 0.002*\"blair\" + 0.002*\"way\" + 0.002*\"like\" + 0.002*\"show\" + 0.002*\"think\" + 0.002*\"next\" + 0.002*\"labour\" + 0.002*\"first\" + 0.002*\"two\" + 0.002*\"get\" + 0.002*\"minister\" + 0.002*\"many\" + 0.002*\"top\" + 0.002*\"well\" + 0.002*\"added\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 22:05:17.124412. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "lda5.print_topics(5, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo entrenamiento, es posible visualizar los 5 tópicos (0, 1, 2, 3 y 4) encontrados, con sus respectivas distribución de palabras. Al igual que en el primer entrenamiento es posible observar la baja proporción de cada palabra en cada tópico.\n",
    "\n",
    "A pesar que se esperaría que cada tópico hable sobre un tema del corpus, es posible observar que la información entregada por cada tópico no es muy descriptiva, al igual que en el caso anterior, con 3 tópicos. En general, las palabras mostradas con mayor proporción no son muy informativas, por lo que no queda claro que es lo que se intenta representar en cada tópico. Sin embargo, de cada tópico se podría decir que:\n",
    "* Primer tópico: Trataría mayormente de deporte, debido a las palabras *games*, *game* y *players* que aparecen como \"palabras claves\", aunque la palabra *government* puede inducir a una relación entre el deporte y la política.\n",
    "* Segundo tópico: No es posible decir con cierta seguridad de que trata el tópico, dado que tiene \"palabras claves\" como *government* relacionado con politica, *film* relacionado con entretención y *game* relacionado con deporte o entretención.\n",
    "* Tercer tópico: Se podría decir que el tópico habla de entretemiento por contener palabras como *film* o *music*, pero también estaría relacionado con política debido a *government*.\n",
    "* Cuarto tópico: Al igual que en tópico anterior, se podría decir que el tópico está relacionado con entreteniemitno dado que tiene \"palabras claves\" como *film*, *music* y *game*. Aunque también estaría relacionado con política debido a *government*.\n",
    "* Quinto tópico: Se podría pensar que el tópico habla de política dado que tiene palabras como *blair*, *first* y *minister*, pues Tony Blair fue Primer Ministro de Reino Unido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.004*\"could\" + 0.004*\"last\" + 0.003*\"first\" + 0.003*\"government\" + 0.003*\"years\" + 0.003*\"says\" + 0.002*\"get\" + 0.002*\"like\" + 0.002*\"make\" + 0.002*\"way\" + 0.002*\"bbc\" + 0.002*\"time\" + 0.002*\"blair\" + 0.002*\"work\" + 0.002*\"well\" + 0.002*\"sales\" + 0.002*\"users\" + 0.002*\"market\" + 0.002*\"games\" + 0.002*\"good\"'),\n",
       " (1,\n",
       "  u'0.004*\"years\" + 0.004*\"time\" + 0.004*\"last\" + 0.003*\"game\" + 0.003*\"could\" + 0.003*\"make\" + 0.003*\"first\" + 0.003*\"world\" + 0.003*\"club\" + 0.002*\"think\" + 0.002*\"league\" + 0.002*\"two\" + 0.002*\"good\" + 0.002*\"added\" + 0.002*\"growth\" + 0.002*\"economy\" + 0.002*\"many\" + 0.002*\"may\" + 0.002*\"three\" + 0.002*\"liverpool\"'),\n",
       " (2,\n",
       "  u'0.004*\"could\" + 0.004*\"game\" + 0.004*\"government\" + 0.003*\"last\" + 0.003*\"get\" + 0.003*\"first\" + 0.002*\"made\" + 0.002*\"time\" + 0.002*\"number\" + 0.002*\"back\" + 0.002*\"three\" + 0.002*\"two\" + 0.002*\"show\" + 0.002*\"club\" + 0.002*\"group\" + 0.002*\"may\" + 0.002*\"united\" + 0.002*\"top\" + 0.002*\"next\" + 0.002*\"make\"'),\n",
       " (3,\n",
       "  u'0.004*\"first\" + 0.003*\"last\" + 0.003*\"years\" + 0.003*\"time\" + 0.003*\"two\" + 0.003*\"many\" + 0.002*\"made\" + 0.002*\"world\" + 0.002*\"take\" + 0.002*\"added\" + 0.002*\"chelsea\" + 0.002*\"make\" + 0.002*\"get\" + 0.002*\"think\" + 0.002*\"next\" + 0.002*\"could\" + 0.002*\"minister\" + 0.002*\"like\" + 0.002*\"week\" + 0.002*\"government\"'),\n",
       " (4,\n",
       "  u'0.004*\"could\" + 0.003*\"two\" + 0.003*\"deal\" + 0.003*\"first\" + 0.002*\"film\" + 0.002*\"make\" + 0.002*\"last\" + 0.002*\"government\" + 0.002*\"get\" + 0.002*\"game\" + 0.002*\"way\" + 0.002*\"take\" + 0.002*\"still\" + 0.002*\"show\" + 0.002*\"bbc\" + 0.002*\"back\" + 0.002*\"want\" + 0.002*\"many\" + 0.002*\"next\" + 0.002*\"says\"'),\n",
       " (5,\n",
       "  u'0.004*\"government\" + 0.003*\"could\" + 0.003*\"film\" + 0.003*\"last\" + 0.003*\"years\" + 0.003*\"home\" + 0.002*\"two\" + 0.002*\"well\" + 0.002*\"labour\" + 0.002*\"time\" + 0.002*\"dont\" + 0.002*\"like\" + 0.002*\"music\" + 0.002*\"back\" + 0.002*\"bbc\" + 0.002*\"added\" + 0.002*\"award\" + 0.002*\"made\" + 0.002*\"many\" + 0.002*\"think\"'),\n",
       " (6,\n",
       "  u'0.004*\"music\" + 0.004*\"number\" + 0.003*\"years\" + 0.003*\"could\" + 0.003*\"two\" + 0.003*\"last\" + 0.003*\"band\" + 0.002*\"album\" + 0.002*\"british\" + 0.002*\"like\" + 0.002*\"time\" + 0.002*\"back\" + 0.002*\"three\" + 0.002*\"first\" + 0.002*\"world\" + 0.002*\"club\" + 0.002*\"show\" + 0.002*\"get\" + 0.002*\"film\" + 0.002*\"bbc\"'),\n",
       " (7,\n",
       "  u'0.004*\"time\" + 0.004*\"labour\" + 0.004*\"blair\" + 0.003*\"election\" + 0.003*\"two\" + 0.003*\"could\" + 0.003*\"first\" + 0.003*\"last\" + 0.003*\"made\" + 0.002*\"number\" + 0.002*\"say\" + 0.002*\"games\" + 0.002*\"three\" + 0.002*\"world\" + 0.002*\"top\" + 0.002*\"may\" + 0.002*\"years\" + 0.002*\"get\" + 0.002*\"bbc\" + 0.002*\"party\"'),\n",
       " (8,\n",
       "  u'0.003*\"many\" + 0.003*\"film\" + 0.003*\"could\" + 0.003*\"government\" + 0.003*\"last\" + 0.002*\"years\" + 0.002*\"law\" + 0.002*\"added\" + 0.002*\"bbc\" + 0.002*\"time\" + 0.002*\"top\" + 0.002*\"first\" + 0.002*\"good\" + 0.002*\"two\" + 0.002*\"like\" + 0.002*\"lord\" + 0.002*\"music\" + 0.002*\"use\" + 0.002*\"take\" + 0.002*\"minister\"'),\n",
       " (9,\n",
       "  u'0.004*\"years\" + 0.003*\"made\" + 0.003*\"last\" + 0.003*\"could\" + 0.003*\"government\" + 0.003*\"bbc\" + 0.003*\"time\" + 0.003*\"first\" + 0.002*\"game\" + 0.002*\"company\" + 0.002*\"security\" + 0.002*\"make\" + 0.002*\"two\" + 0.002*\"well\" + 0.002*\"still\" + 0.002*\"many\" + 0.002*\"service\" + 0.002*\"use\" + 0.002*\"minister\" + 0.002*\"way\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:29:23.741746. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "lda10.print_topics(10, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el tercer entrenamiento, es posible visualizar los 10 tópicos (0, 1, 2,..., 9) encontrados, con sus respectivas distribución de palabras. Al igual que en los entrenamiento anteriores es posible observar la baja proporción de cada palabra en cada tópico.\n",
    "\n",
    "Es posible observar que la mayor parte de la información entregada por cada tópico no es muy descriptiva, al igual que en los casos anterior. En general, las palabras mostradas con mayor proporción no son muy informativas, por lo que no queda claro que es lo que se intenta representar en cada tópico. A pesar de esto,  se podría decir de cada tópico que:\n",
    "\n",
    "* Primer tópico: Es un tópico bien variado, que contiene información sobre política debido a la aparición de las palabras *government* y *blair*, además contiene información sobre negocios por palabras como *work*, *market* y *sales*, y también se podría pensar que se está hablando de tecnología por la palabra *users* y de entretención o deporte por *games*. \n",
    "* Segundo tópico: En este tópico se estaría hablando mayormente sobre deporte, por palabras como *game*, *club*, *league* y *liverpool*, pero también estaría relacionado con negocios o política por la palabra *economy*. \n",
    "* Tercer tópico: Este tópico también tendría más presente el tema deporte (*game*, *club*) pero no tan marcadamente como en el tópico anterior.         \n",
    "* Cuarto tópico: El tópico tendría más presente el tema político debido a palabras clave como *minister* y *government*, a pesar que estas aparezcan con menor probabiliad que las otras palabras, pues ellas no son informativas.\n",
    "* Quinto tópico: film government game \n",
    "* Sexto tópico: governmen film music award\n",
    "* Septimo tópico: music band album british club film -> claramente entrtencion\n",
    "* Octavo tópico: blair election games party\n",
    "* Noveno tópico: film government law lord music minister -> politica con un poco de entretención xd\n",
    "* Décimo tópico: government game company security minister\n",
    "\n",
    "Se esperaria que el topico 5 es mejor y cada uno represente un tema ...\n",
    "10 topicos aparecen nuevas palabras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parte 3: Dynamic Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Dynamic Topic Models (DTM) también es un modelo generativo extendido de LDA, pero que a diferencia de éste permite analizar la evolución de los tópicos en un corpus a través del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[//]: <> (Primera pregunta)\n",
    "Primero se procede a entrenar nuevamente el corpus entregado, pero esta vez utilizando el algoritmo LdaSeq, el cual está basado en el código orginal de DTM de Blei. Para el entrenamiento se utilizarán 5 tópicos con una varianza *0.001*, y además se debe entregar como parámetro la cantidad de documentos por intervalo de tiempo, que en este caso serían los documentos para cada mes, con 3 intervalos de tiempo, dado que los documentos pertenecen a 3 meses (marzo, abril y mayo): 438 documentos para el primer intervalo, 430 para e segundo intervalo y 456 para el último intervalo.\n",
    "\n",
    "Al igual que el LDA, se introduce el parámetro *id2word=dictionary* en la ejecución, para realizar el pareo entre el id de las palabras del diccionario y las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-10 23:20:21.065411. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import ldaseqmodel\n",
    "\n",
    "time_slice = [438, 430, 456]\n",
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5, chain_variance = 0.001)\n",
    "ldaseq.save(\"res_ldaseq/ldaseq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Segunda pregunta Para cada uno de los intervalos de tiempo, observe la distribución topic_word de cada tópico ¿Que puede observar en la evolución de estos?)\n",
    "\n",
    "A continuación se muestra el resultado de obtenido de LdaSeq, el cual entrega todos los tópicos en un intervalo de tiempo específico, dado que la ejecución solo se realizó con 5 tópicos, la únca variación es el intervalo de tiempo a visualizar. La cantidad de palabras a mostrar para cada tópico serán las por defecto, 20.\n",
    "\n",
    "En el primer intervalo, que se asume el marzo de 2016 se obtiene la siguiente distribución de palabras para cada tópico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(u'market', 0.005),\n",
      "  (u'last', 0.004),\n",
      "  (u'government', 0.004),\n",
      "  (u'years', 0.004),\n",
      "  (u'growth', 0.004),\n",
      "  (u'economy', 0.004),\n",
      "  (u'economic', 0.003),\n",
      "  (u'could', 0.003),\n",
      "  (u'bank', 0.003),\n",
      "  (u'company', 0.003),\n",
      "  (u'oil', 0.003),\n",
      "  (u'sales', 0.003),\n",
      "  (u'prices', 0.003),\n",
      "  (u'however', 0.003),\n",
      "  (u'firm', 0.003),\n",
      "  (u'may', 0.003),\n",
      "  (u'rise', 0.003),\n",
      "  (u'shares', 0.002),\n",
      "  (u'business', 0.002),\n",
      "  (u'european', 0.002)],\n",
      " [(u'could', 0.006),\n",
      "  (u'use', 0.005),\n",
      "  (u'technology', 0.005),\n",
      "  (u'many', 0.005),\n",
      "  (u'users', 0.005),\n",
      "  (u'games', 0.004),\n",
      "  (u'online', 0.004),\n",
      "  (u'information', 0.004),\n",
      "  (u'mobile', 0.004),\n",
      "  (u'net', 0.004),\n",
      "  (u'software', 0.004),\n",
      "  (u'service', 0.003),\n",
      "  (u'used', 0.003),\n",
      "  (u'get', 0.003),\n",
      "  (u'using', 0.003),\n",
      "  (u'make', 0.003),\n",
      "  (u'computer', 0.003),\n",
      "  (u'phone', 0.003),\n",
      "  (u'digital', 0.003),\n",
      "  (u'internet', 0.003)],\n",
      " [(u'game', 0.009),\n",
      "  (u'club', 0.007),\n",
      "  (u'chelsea', 0.007),\n",
      "  (u'players', 0.006),\n",
      "  (u'united', 0.006),\n",
      "  (u'league', 0.006),\n",
      "  (u'football', 0.005),\n",
      "  (u'arsenal', 0.005),\n",
      "  (u'cup', 0.005),\n",
      "  (u'play', 0.005),\n",
      "  (u'win', 0.005),\n",
      "  (u'time', 0.004),\n",
      "  (u'manager', 0.004),\n",
      "  (u'back', 0.004),\n",
      "  (u'first', 0.004),\n",
      "  (u'goal', 0.004),\n",
      "  (u'liverpool', 0.004),\n",
      "  (u'team', 0.004),\n",
      "  (u'last', 0.004),\n",
      "  (u'good', 0.004)],\n",
      " [(u'film', 0.01),\n",
      "  (u'music', 0.009),\n",
      "  (u'show', 0.007),\n",
      "  (u'years', 0.006),\n",
      "  (u'number', 0.005),\n",
      "  (u'awards', 0.005),\n",
      "  (u'first', 0.005),\n",
      "  (u'last', 0.005),\n",
      "  (u'band', 0.004),\n",
      "  (u'award', 0.004),\n",
      "  (u'top', 0.004),\n",
      "  (u'album', 0.004),\n",
      "  (u'star', 0.004),\n",
      "  (u'song', 0.004),\n",
      "  (u'two', 0.003),\n",
      "  (u'three', 0.003),\n",
      "  (u'including', 0.003),\n",
      "  (u'british', 0.003),\n",
      "  (u'director', 0.003),\n",
      "  (u'bbc', 0.003)],\n",
      " [(u'government', 0.007),\n",
      "  (u'blair', 0.006),\n",
      "  (u'labour', 0.006),\n",
      "  (u'minister', 0.005),\n",
      "  (u'election', 0.005),\n",
      "  (u'party', 0.004),\n",
      "  (u'bbc', 0.004),\n",
      "  (u'could', 0.004),\n",
      "  (u'public', 0.004),\n",
      "  (u'say', 0.004),\n",
      "  (u'brown', 0.004),\n",
      "  (u'prime', 0.004),\n",
      "  (u'plans', 0.003),\n",
      "  (u'howard', 0.003),\n",
      "  (u'law', 0.003),\n",
      "  (u'says', 0.003),\n",
      "  (u'lord', 0.003),\n",
      "  (u'secretary', 0.003),\n",
      "  (u'next', 0.003),\n",
      "  (u'leader', 0.003)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:36:53.279685. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el segundo intervalo, que se asume el abril de 2016 se obtiene la siguiente distribución de palabras para cada tópico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'market', 0.005),\n",
       "  (u'last', 0.004),\n",
       "  (u'government', 0.004),\n",
       "  (u'years', 0.004),\n",
       "  (u'growth', 0.004),\n",
       "  (u'economy', 0.004),\n",
       "  (u'economic', 0.003),\n",
       "  (u'could', 0.003),\n",
       "  (u'bank', 0.003),\n",
       "  (u'oil', 0.003),\n",
       "  (u'company', 0.003),\n",
       "  (u'sales', 0.003),\n",
       "  (u'prices', 0.003),\n",
       "  (u'however', 0.003),\n",
       "  (u'firm', 0.003),\n",
       "  (u'may', 0.003),\n",
       "  (u'rise', 0.003),\n",
       "  (u'shares', 0.002),\n",
       "  (u'european', 0.002),\n",
       "  (u'business', 0.002)],\n",
       " [(u'could', 0.006),\n",
       "  (u'use', 0.005),\n",
       "  (u'technology', 0.005),\n",
       "  (u'many', 0.005),\n",
       "  (u'users', 0.005),\n",
       "  (u'games', 0.004),\n",
       "  (u'online', 0.004),\n",
       "  (u'information', 0.004),\n",
       "  (u'net', 0.004),\n",
       "  (u'mobile', 0.004),\n",
       "  (u'software', 0.004),\n",
       "  (u'get', 0.003),\n",
       "  (u'used', 0.003),\n",
       "  (u'service', 0.003),\n",
       "  (u'using', 0.003),\n",
       "  (u'make', 0.003),\n",
       "  (u'computer', 0.003),\n",
       "  (u'phone', 0.003),\n",
       "  (u'digital', 0.003),\n",
       "  (u'internet', 0.003)],\n",
       " [(u'game', 0.009),\n",
       "  (u'club', 0.007),\n",
       "  (u'chelsea', 0.007),\n",
       "  (u'players', 0.006),\n",
       "  (u'united', 0.006),\n",
       "  (u'league', 0.006),\n",
       "  (u'football', 0.005),\n",
       "  (u'arsenal', 0.005),\n",
       "  (u'cup', 0.005),\n",
       "  (u'win', 0.005),\n",
       "  (u'play', 0.005),\n",
       "  (u'time', 0.004),\n",
       "  (u'manager', 0.004),\n",
       "  (u'back', 0.004),\n",
       "  (u'first', 0.004),\n",
       "  (u'goal', 0.004),\n",
       "  (u'liverpool', 0.004),\n",
       "  (u'team', 0.004),\n",
       "  (u'last', 0.004),\n",
       "  (u'good', 0.004)],\n",
       " [(u'film', 0.01),\n",
       "  (u'music', 0.009),\n",
       "  (u'show', 0.007),\n",
       "  (u'years', 0.006),\n",
       "  (u'number', 0.005),\n",
       "  (u'awards', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'first', 0.005),\n",
       "  (u'top', 0.004),\n",
       "  (u'band', 0.004),\n",
       "  (u'award', 0.004),\n",
       "  (u'album', 0.004),\n",
       "  (u'star', 0.004),\n",
       "  (u'song', 0.004),\n",
       "  (u'two', 0.003),\n",
       "  (u'three', 0.003),\n",
       "  (u'including', 0.003),\n",
       "  (u'british', 0.003),\n",
       "  (u'bbc', 0.003),\n",
       "  (u'director', 0.003)],\n",
       " [(u'government', 0.007),\n",
       "  (u'blair', 0.006),\n",
       "  (u'labour', 0.006),\n",
       "  (u'minister', 0.005),\n",
       "  (u'election', 0.005),\n",
       "  (u'party', 0.004),\n",
       "  (u'bbc', 0.004),\n",
       "  (u'public', 0.004),\n",
       "  (u'could', 0.004),\n",
       "  (u'say', 0.004),\n",
       "  (u'brown', 0.004),\n",
       "  (u'prime', 0.004),\n",
       "  (u'plans', 0.003),\n",
       "  (u'howard', 0.003),\n",
       "  (u'law', 0.003),\n",
       "  (u'says', 0.003),\n",
       "  (u'lord', 0.003),\n",
       "  (u'secretary', 0.003),\n",
       "  (u'next', 0.003),\n",
       "  (u'police', 0.003)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:38:03.369407. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último intervalo, que se asume el mayo de 2016 se obtiene la siguiente distribución de palabras para cada tópico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'market', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'government', 0.004),\n",
       "  (u'years', 0.004),\n",
       "  (u'growth', 0.004),\n",
       "  (u'economy', 0.004),\n",
       "  (u'economic', 0.003),\n",
       "  (u'could', 0.003),\n",
       "  (u'bank', 0.003),\n",
       "  (u'oil', 0.003),\n",
       "  (u'company', 0.003),\n",
       "  (u'sales', 0.003),\n",
       "  (u'however', 0.003),\n",
       "  (u'prices', 0.003),\n",
       "  (u'firm', 0.003),\n",
       "  (u'may', 0.003),\n",
       "  (u'rise', 0.003),\n",
       "  (u'shares', 0.002),\n",
       "  (u'european', 0.002),\n",
       "  (u'business', 0.002)],\n",
       " [(u'could', 0.006),\n",
       "  (u'use', 0.005),\n",
       "  (u'technology', 0.005),\n",
       "  (u'many', 0.005),\n",
       "  (u'users', 0.005),\n",
       "  (u'games', 0.004),\n",
       "  (u'online', 0.004),\n",
       "  (u'information', 0.004),\n",
       "  (u'net', 0.004),\n",
       "  (u'mobile', 0.004),\n",
       "  (u'software', 0.004),\n",
       "  (u'service', 0.003),\n",
       "  (u'used', 0.003),\n",
       "  (u'get', 0.003),\n",
       "  (u'using', 0.003),\n",
       "  (u'make', 0.003),\n",
       "  (u'phone', 0.003),\n",
       "  (u'computer', 0.003),\n",
       "  (u'digital', 0.003),\n",
       "  (u'internet', 0.003)],\n",
       " [(u'game', 0.009),\n",
       "  (u'club', 0.007),\n",
       "  (u'chelsea', 0.007),\n",
       "  (u'players', 0.006),\n",
       "  (u'united', 0.006),\n",
       "  (u'league', 0.006),\n",
       "  (u'football', 0.005),\n",
       "  (u'arsenal', 0.005),\n",
       "  (u'cup', 0.005),\n",
       "  (u'win', 0.005),\n",
       "  (u'play', 0.004),\n",
       "  (u'time', 0.004),\n",
       "  (u'manager', 0.004),\n",
       "  (u'back', 0.004),\n",
       "  (u'first', 0.004),\n",
       "  (u'goal', 0.004),\n",
       "  (u'liverpool', 0.004),\n",
       "  (u'team', 0.004),\n",
       "  (u'last', 0.004),\n",
       "  (u'manchester', 0.004)],\n",
       " [(u'film', 0.009),\n",
       "  (u'music', 0.009),\n",
       "  (u'show', 0.007),\n",
       "  (u'years', 0.006),\n",
       "  (u'number', 0.005),\n",
       "  (u'awards', 0.005),\n",
       "  (u'last', 0.005),\n",
       "  (u'first', 0.005),\n",
       "  (u'band', 0.004),\n",
       "  (u'top', 0.004),\n",
       "  (u'award', 0.004),\n",
       "  (u'album', 0.004),\n",
       "  (u'song', 0.004),\n",
       "  (u'star', 0.004),\n",
       "  (u'two', 0.003),\n",
       "  (u'three', 0.003),\n",
       "  (u'including', 0.003),\n",
       "  (u'british', 0.003),\n",
       "  (u'bbc', 0.003),\n",
       "  (u'chart', 0.003)],\n",
       " [(u'government', 0.007),\n",
       "  (u'blair', 0.006),\n",
       "  (u'labour', 0.006),\n",
       "  (u'minister', 0.005),\n",
       "  (u'election', 0.005),\n",
       "  (u'party', 0.004),\n",
       "  (u'bbc', 0.004),\n",
       "  (u'public', 0.004),\n",
       "  (u'say', 0.004),\n",
       "  (u'brown', 0.004),\n",
       "  (u'could', 0.004),\n",
       "  (u'prime', 0.004),\n",
       "  (u'plans', 0.003),\n",
       "  (u'howard', 0.003),\n",
       "  (u'says', 0.003),\n",
       "  (u'law', 0.003),\n",
       "  (u'lord', 0.003),\n",
       "  (u'secretary', 0.003),\n",
       "  (u'next', 0.003),\n",
       "  (u'leader', 0.003)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 00:38:09.769931. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ldaseq.print_topics(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Tercera pregunta Para un documento dado del corpus , obtenga la distribución de tópicos usando el modelo entrenado y visualice el contenido de dicho documento. Analice sus observaciones. Repita el experimento con los 3 modelos generados.)\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call corpus[docid] without an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-847f39c61227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m558\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdoc_bow\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mldaseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_bow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/corpora/indexedcorpus.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, docno)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot call corpus[docid] without an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call corpus[docid] without an index"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:275: DeprecationWarning: Interpreting naive datetime as local 2017-06-11 02:12:24.518355. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "words = [dictionary[word_id] for word_id, count in corpus[558]]\n",
    "print (words)\n",
    "doc_bow =30  #QUE ES!!!\n",
    "print (ldaseq[doc_bow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (Cuarta pregunta Instale el módulo pyLDAvis para visualizar el modelo generado por LDAseq se recomienda usar el paquete pip para instalar pyLDAvis. Genere una visualización para cada intervalo de tiempo modifique el parámetro time)  \n",
    "\n",
    "A continuación mediante el módulo pyLDAvis se genera una visualización para cada intervalo de tiempo.\n",
    "\n",
    "Para el primer intervalo de tiempo (marzo) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=0, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo intervalo de tiempo (abril) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=1, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el último intervalo de tiempo (mayo) se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = ldaseq.dtm_vis(time=2, corpus=corpus)\n",
    "vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.display(vis_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: <> (quinta pregunta Compare los resultados obtenidos con el modelo LDA de la sección anterior, con los resultados de ldaseq ¿Que modelo logra representar mejor el corpus de documentos usado? ¿Como influye en el entrenamiento de los tópicos la consideración de los intervalos de tiempo?.)\n",
    "\n",
    "Al comparar los resultados entregados por LDA y LdaSeq es posible determinar que para este corpus son mejores los resultados entregados por el algoritmo de LdaSeq."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
